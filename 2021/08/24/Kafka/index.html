<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"extrali.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="1 Kafka概述1.1 定义Kafka 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue） ， 主要应用于大数据实时处理领域。   1.2 消息队列1.2.1 传统消息队列的应用场景、 使用消息队列好处  解耦   允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。  可恢复性系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka">
<meta property="og:url" content="http://extrali.com/2021/08/24/Kafka/index.html">
<meta property="og:site_name" content="Extrali">
<meta property="og:description" content="1 Kafka概述1.1 定义Kafka 是一个分布式的基于发布&#x2F;订阅模式的消息队列（Message Queue） ， 主要应用于大数据实时处理领域。   1.2 消息队列1.2.1 传统消息队列的应用场景、 使用消息队列好处  解耦   允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。  可恢复性系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以">
<meta property="og:image" content="https://i.loli.net/2021/08/29/bhaXuFQUj8poE4A.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/vKHwqUcN1F4riJn.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/fXHZ8NrcVTFghRm.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/BwG1mf6K9zP7A2H.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/1B7DeiXFnAdz94R.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/nim9obKMrXIlBu5.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/CjRaA2wIP4OzFUm.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/XYTHAUvksoMIVat.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/TasCyYfQ5uBELIJ.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/j5esYdzm1DOBcxg.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/dZvJMmHUViKA2hN.png">
<meta property="og:image" content="c:%5CUsers%5Cextra%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210829153604369.png">
<meta property="og:image" content="https://i.loli.net/2021/08/29/4N1kchtIQYpRix5.png">
<meta property="article:published_time" content="2021-08-24T15:32:08.000Z">
<meta property="article:modified_time" content="2021-08-29T08:33:18.776Z">
<meta property="article:author" content="黎达">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/08/29/bhaXuFQUj8poE4A.png">

<link rel="canonical" href="http://extrali.com/2021/08/24/Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>Kafka | Extrali</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="تشغيل شريط التصفح">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Extrali</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>الأرشيفات</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="http://extrali.com/2021/08/24/Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="黎达">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Extrali">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">نُشر في</span>

              <time title="أُنشأ: 2021-08-24 23:32:08" itemprop="dateCreated datePublished" datetime="2021-08-24T23:32:08+08:00">2021-08-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">عُدل في</span>
                <time title="عُدل: 2021-08-29 16:33:18" itemprop="dateModified" datetime="2021-08-29T16:33:18+08:00">2021-08-29</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">في</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-Kafka概述"><a href="#1-Kafka概述" class="headerlink" title="1 Kafka概述"></a>1 Kafka概述</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p>Kafka 是一个<strong>分布式</strong>的基于<strong>发布/订阅模式</strong>的<strong>消息队列</strong>（Message Queue） ， 主要应用于<strong>大数据实时</strong>处理领域。  </p>
<h2 id="1-2-消息队列"><a href="#1-2-消息队列" class="headerlink" title="1.2 消息队列"></a>1.2 消息队列</h2><h3 id="1-2-1-传统消息队列的应用场景"><a href="#1-2-1-传统消息队列的应用场景" class="headerlink" title="1.2.1 传统消息队列的应用场景"></a>1.2.1 传统消息队列的应用场景</h3><p><img src="https://i.loli.net/2021/08/29/bhaXuFQUj8poE4A.png" alt="image-20210829100457579">、</p>
<p><strong>使用消息队列好处</strong></p>
<ol>
<li><p><strong>解耦</strong>  </p>
<p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
</li>
<li><p><strong>可恢复性</strong><br>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。  </p>
</li>
<li><p><strong>缓冲</strong>  </p>
<p>有助于控制和优化数据流经过系统的速度， 解决生产消息和消费消息的处理速度不一致的情况。 </p>
</li>
<li><p><strong>灵活性 &amp; 峰值处理能力</strong><br>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。  </p>
</li>
<li><p>异步通信</p>
<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。  </p>
</li>
</ol>
<h3 id="1-2-2-消息队列的两种模式"><a href="#1-2-2-消息队列的两种模式" class="headerlink" title="1.2.2 消息队列的两种模式"></a>1.2.2 消息队列的两种模式</h3><ol>
<li><p><strong>点对点模式</strong>（一对一，消费者主动拉取数据，消息收到后消息清除）  </p>
<p>消息生产者生产消息发送到Queue中， 然后消息消费者从Queue中取出并且消费消息。消息被消费以后， queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。  </p>
<p><img src="https://i.loli.net/2021/08/29/vKHwqUcN1F4riJn.png" alt="image-20210829100905235"></p>
</li>
<li><p><strong>发布/订阅模式</strong>（一对多，消费者消费数据之后不会清除消息 ）</p>
<p>消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。  </p>
<p><img src="https://i.loli.net/2021/08/29/fXHZ8NrcVTFghRm.png" alt="image-20210829101011829"></p>
</li>
</ol>
<h2 id="1-3-Kafka基础架构"><a href="#1-3-Kafka基础架构" class="headerlink" title="1.3 Kafka基础架构"></a>1.3 Kafka基础架构</h2><p><img src="https://i.loli.net/2021/08/29/BwG1mf6K9zP7A2H.png" alt="image-20210829101042834"></p>
<ol>
<li><strong>Producer</strong> ： 消息生产者，就是向 kafka broker 发消息的客户端；</li>
<li><strong>Consumer</strong> ： 消息消费者，向 kafka broker 取消息的客户端；</li>
<li><strong>Consumer Group （CG）</strong>： 消费者组，由多个 consumer 组成。 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。 所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>
<li><strong>Broker</strong> ： 一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic。 </li>
<li><strong>Topic</strong> ： 可以理解为一个队列， 生产者和消费者面向的都是一个 topic；</li>
<li><strong>Partition</strong>： 为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，<strong>一个 topic 可以分为多个 partition</strong>，每个 partition 是一个有序的队列； </li>
<li><strong>Replica</strong>： 副本，为保证集群中的某个节点发生故障时， 该节点上的 partition 数据不丢失，且 kafka 仍然能够继续工作， kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 <strong>leader</strong> 和若干个 <strong>follower</strong>。  </li>
<li><strong>leader</strong>： 每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。</li>
<li><strong>follower</strong>： 每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。 leader 发生故障时，某个 follower 会成为新的 follower。  </li>
</ol>
<h1 id="2-Kafka架构深入"><a href="#2-Kafka架构深入" class="headerlink" title="2 Kafka架构深入"></a>2 Kafka架构深入</h1><h2 id="2-1-Kafka工作流程及文件存储机制"><a href="#2-1-Kafka工作流程及文件存储机制" class="headerlink" title="2.1 Kafka工作流程及文件存储机制"></a>2.1 Kafka工作流程及文件存储机制</h2><p><img src="https://i.loli.net/2021/08/29/1B7DeiXFnAdz94R.png" alt="image-20210829101614958"></p>
<p>Kafka 中消息是以 topic 进行分类的， 生产者生产消息，消费者消费消息，都是面向 topic的。  </p>
<p>topic 是逻辑上的概念，而 partition 是物理上的概念，<strong>每个 partition 对应于一个 log 文件</strong>，该 log 文件中存储的就是 producer 生产的数据。 Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。 消费者组中的每个消费者， 都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。  </p>
<p><img src="https://i.loli.net/2021/08/29/nim9obKMrXIlBu5.png" alt="image-20210829101808522"></p>
<p>由于生产者生产的消息会不断追加到 log 文件末尾， 为防止 log 文件过大导致数据定位效率低下， Kafka 采取了分片和索引机制，将每个 partition 分为多个 <strong>segment</strong>。 每个 segment对应两个文件——“.index”文件和“.log”文件。 这些文件位于一个文件夹下， 该文件夹的命名规则为： topic 名称+分区序号。例如， first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">00000000000000000000.index</span><br><span class="line">00000000000000000000.log</span><br><span class="line">00000000000000170410.index</span><br><span class="line">00000000000000170410.log</span><br><span class="line">00000000000000239430.index</span><br><span class="line">00000000000000239430.log</span><br></pre></td></tr></table></figure>

<p>index 和 log 文件以<strong>当前 segment 的第一条消息的 offset 命名</strong>。下图为 index 文件和 log文件的结构示意图。  </p>
<p><img src="https://i.loli.net/2021/08/29/CjRaA2wIP4OzFUm.png" alt="image-20210829101927517"></p>
<p>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，<strong>索引文件中的元数据指向对应数据文件中 message 的物理偏移地址</strong>。  </p>
<h2 id="2-2-Kafka生产者"><a href="#2-2-Kafka生产者" class="headerlink" title="2.2 Kafka生产者"></a>2.2 Kafka生产者</h2><h3 id="2-2-1-分区策略"><a href="#2-2-1-分区策略" class="headerlink" title="2.2.1 分区策略"></a>2.2.1 分区策略</h3><ol>
<li><p>分区的原因</p>
<ul>
<li><strong>方便在集群中扩展</strong>，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应任意大小的数据了；</li>
<li>可以<strong>提高并发</strong>，因为可以以 Partition 为单位读写了。  </li>
</ul>
</li>
<li><p>分区的原因</p>
<p>我们需要将 producer 发送的数据封装成一个 <strong>ProducerRecord</strong> 对象。  </p>
<p><img src="https://i.loli.net/2021/08/29/XYTHAUvksoMIVat.png" alt="image-20210829102228983"></p>
<ul>
<li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；  </li>
<li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值；</li>
<li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition值，也就是常说的 <strong>round-robin</strong> 算法。  </li>
</ul>
</li>
</ol>
<h3 id="2-2-2-数据可靠性保证"><a href="#2-2-2-数据可靠性保证" class="headerlink" title="2.2.2 数据可靠性保证"></a>2.2.2 数据可靠性保证</h3><p>为保证 producer 发送的数据，能可靠的发送到指定的 topic， <strong>topic</strong> 的每个 partition 收到producer 发送的数据后， 都需要向 producer 发送 <strong>ack</strong>（acknowledgement 确认收到） ，<strong>如果producer 收到 ack， 就会进行下一轮的发送，否则重新发送数据</strong>。  </p>
<p><img src="https://i.loli.net/2021/08/29/TasCyYfQ5uBELIJ.png" alt="image-20210829102436502"></p>
<ol>
<li><p>副本数据同步策略</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody><tr>
<td>半数以上完成同步， 就发 送 ack</td>
<td>延迟低</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 2n+1 个副 本</td>
</tr>
<tr>
<td>全部完成同步，才发送 ack</td>
<td>选举新的 leader 时， 容忍 n 台 节点的故障，需要 n+1 个副 本</td>
<td>延迟高</td>
</tr>
</tbody></table>
<p>Kafka 选择了第二种方案，原因如下：<br>1.同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而 Kafka 的每个分区都有大量的数据， 第一种方案会造成大量数据的冗余。<br>2.虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。  </p>
</li>
<li><p><strong>ISR</strong></p>
<p>采用第二种方案之后，设想以下情景： leader 收到数据，所有 follower 都开始同步数据，但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，直到它完成同步，才能发送 ack。这个问题怎么解决呢？ </p>
<p>Leader 维护了一个动态的 <strong>in-sync replica set (ISR)</strong>，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后， leader 就会给 follower 发送 ack。如果 follower长 时 间 未 向 leader 同 步 数 据 ， 则 该 follower 将 被 踢 出 ISR ， 该 时 间 阈 值 由replica.lag.time.max.ms 参数设定。 Leader 发生故障之后，就会从 ISR 中选举新的 leader。  </p>
</li>
<li><p><strong>ack 应答机制</strong><br>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。  </p>
<p><strong>acks 参数配置：</strong><br>acks：<br><strong>0</strong>： producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟， broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据；<br><strong>1</strong>： producer 等待 broker 的 ack， partition 的 leader 落盘成功后返回 ack，如果在 follower同步成功之前 leader 故障，那么将会丢失数据；  </p>
<p><strong>-1（all）</strong> ： producer 等待 broker 的 ack， partition 的 leader 和 follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后， broker 发送 ack 之前， leader 发生故障，那么会造成数据重复。  </p>
<p><img src="https://i.loli.net/2021/08/29/j5esYdzm1DOBcxg.png" alt="image-20210829103122680"></p>
</li>
<li><p><strong>故障处理细节</strong></p>
<p><img src="https://i.loli.net/2021/08/29/dZvJMmHUViKA2hN.png" alt="image-20210829103213045"></p>
<p><strong>LEO：指的是每个副本最大的 offset；<br>HW：指的是消费者能见到的最大的 offset， ISR 队列中最小的 LEO。</strong>    </p>
<ol>
<li><p><strong>follower 故障</strong><br>follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后， follower 会读取本地磁盘<strong>记录的上次的 HW</strong>，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。<strong>等该 follower 的 LEO 大于等于该 Partition 的 HW</strong>，即 follower 追上 leader 之后，就可以重新加入 ISR 了。  </p>
</li>
<li><p><strong>leader 故障</strong><br>leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的 数据一致性， <strong>其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉</strong>，然后从新的 leader同步数据。  </p>
</li>
</ol>
<p>*<em>注意： 这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。  *</em></p>
</li>
</ol>
<h3 id="2-2-3-Exactly-Once-语义"><a href="#2-2-3-Exactly-Once-语义" class="headerlink" title="2.2.3 Exactly Once 语义"></a>2.2.3 Exactly Once 语义</h3><p>将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 <strong>AtLeast Once</strong> 语义。相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次，即 <strong>At Most Once</strong> 语义。  </p>
<p>At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的， At Most Once可以保证数据不重复，但是不能保证数据不丢失。 但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即 <strong>Exactly Once</strong> 语义。 在 0.11 版本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。  </p>
<p>0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据， Server 端都只会持久化一条。幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即： </p>
<p>​                                                                <strong>At Least Once + 幂等性 = Exactly Once</strong></p>
<p>要启用幂等性，只需要将 Producer 的参数中 <strong>enable.idompotence</strong> 设置为 true 即可。 Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而Broker 端会对&lt;PID, Partition, SeqNumber&gt;做缓存，当具有相同主键的消息提交时， Broker 只会持久化一条。    </p>
<p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以<strong>幂等性无法保证跨分区跨会话的 Exactly Once</strong>。  </p>
<h2 id="2-3-Kafka消费者"><a href="#2-3-Kafka消费者" class="headerlink" title="2.3 Kafka消费者"></a>2.3 Kafka消费者</h2><h3 id="2-3-1-消费方式"><a href="#2-3-1-消费方式" class="headerlink" title="2.3.1 消费方式"></a>2.3.1 消费方式</h3><p>consumer 采用 <strong>pull（拉）</strong> 模式从 broker 中读取数据。<br>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 <strong>pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息</strong>。 </p>
<p><strong>pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中， 一直返回空数据</strong>。 针对这一点， Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费， consumer 会等待一段时间之后再返回，这段时长即为 timeout。  </p>
<h3 id="2-3-2-分区分配策略"><a href="#2-3-2-分区分配策略" class="headerlink" title="2.3.2 分区分配策略"></a>2.3.2 分区分配策略</h3><p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。<br>Kafka 有两种分配策略，一是 RoundRobin，一是 Range。 </p>
<h3 id="2-3-3-offset的维护"><a href="#2-3-3-offset的维护" class="headerlink" title="2.3.3 offset的维护"></a>2.3.3 offset的维护</h3><p>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故障前的位置的继续消费，所以 <strong>consumer 需要实时记录自己消费到了哪个 offset</strong>，以便故障恢复后继续消费。  </p>
<p>Kafka 0.9 版本之前， consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，<strong>consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中</strong>，该 topic 为__consumer_offsets。  </p>
<h2 id="2-4-Kafka高效读写数据"><a href="#2-4-Kafka高效读写数据" class="headerlink" title="2.4 Kafka高效读写数据"></a>2.4 Kafka高效读写数据</h2><ol>
<li><p><strong>顺序写磁盘</strong></p>
<p>Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。 官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。  </p>
</li>
<li><p><strong>零拷贝</strong></p>
</li>
</ol>
<h2 id="2-5-Zookeeper在Kafka中的作用"><a href="#2-5-Zookeeper在Kafka中的作用" class="headerlink" title="2.5 Zookeeper在Kafka中的作用"></a>2.5 Zookeeper在Kafka中的作用</h2><p>Kafka 集群中有一个 broker 会被选举为 <strong>Controller</strong>，<strong>负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作</strong>。<br>Controller 的管理工作都是依赖于 Zookeeper 的。</p>
<h2 id="2-6-Kafka事务"><a href="#2-6-Kafka事务" class="headerlink" title="2.6 Kafka事务"></a>2.6 Kafka事务</h2><p>Kafka 从 0.11 版本开始引入了事务支持。<strong>事务可以保证 Kafka 在 Exactly Once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</strong>  </p>
<h3 id="2-6-1-Producer事务"><a href="#2-6-1-Producer事务" class="headerlink" title="2.6.1 Producer事务"></a>2.6.1 Producer事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 TransactionID 获得原来的 PID。  </p>
<p>为了管理 Transaction， Kafka 引入了一个新的组件 Transaction Coordinator。 Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。 TransactionCoordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。  </p>
<h3 id="2-6-2-Consumer事务"><a href="#2-6-2-Consumer事务" class="headerlink" title="2.6.2 Consumer事务"></a>2.6.2 Consumer事务</h3><p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对较弱，尤其是无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被删除的情况。  </p>
<h1 id="3-Kafka-API"><a href="#3-Kafka-API" class="headerlink" title="3 Kafka API"></a>3 Kafka API</h1><h2 id="3-1-Producer-API"><a href="#3-1-Producer-API" class="headerlink" title="3.1 Producer API"></a>3.1 Producer API</h2><h3 id="3-1-1-消息发送流程"><a href="#3-1-1-消息发送流程" class="headerlink" title="3.1.1 消息发送流程"></a>3.1.1 消息发送流程</h3><p>Kafka 的 Producer 发送消息采用的是<strong>异步发送</strong>的方式。在消息发送的过程中，涉及到了两个线程——<strong>main 线程和 Sender 线程</strong>，以及一个线程共享变量——<strong>RecordAccumulator</strong>。main 线程将消息发送给 RecordAccumulator， Sender 线程不断从RecordAccumulator 中拉取消息发送到 Kafka broker。  </p>
<p><img src="C:%5CUsers%5Cextra%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210829153604369.png" alt="image-20210829153604369"></p>
<p><strong>相关参数：</strong><br>batch.size： 只有数据积累到 batch.size 之后， sender 才会发送数据。<br>linger.ms： 如果数据迟迟未达到 batch.size， sender 等待 linger.time 之后就会发送数据。  </p>
<h3 id="3-1-2-异步发送API"><a href="#3-1-2-异步发送API" class="headerlink" title="3.1.2 异步发送API"></a>3.1.2 异步发送API</h3><ol>
<li><p><strong>导入依赖</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.11.0.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>编写代码</p>
<p>需要用到的类：<br><strong>KafkaProducer</strong>：需要创建一个生产者对象，用来发送数据<br><strong>ProducerConfig</strong>：获取所需的一系列配置参数<br><strong>ProducerRecord</strong>：每条数据都要封装成一个 ProducerRecord 对象  </p>
<ol>
<li><p><strong>不带回调函数的 API</strong>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.producer.*;</span><br><span class="line">import java.util.Properties;</span><br><span class="line">import java.util.concurrent.ExecutionException;</span><br><span class="line"></span><br><span class="line">public class CustomProducer &#123;</span><br><span class="line">    public static void main(String[] args) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">    </span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        &#x2F;&#x2F;kafka 集群， broker-list</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);</span><br><span class="line">        props.put(&quot;acks&quot;, &quot;all&quot;);</span><br><span class="line">        &#x2F;&#x2F;重试次数</span><br><span class="line">        props.put(&quot;retries&quot;, 1);</span><br><span class="line">        &#x2F;&#x2F;批次大小</span><br><span class="line">        props.put(&quot;batch.size&quot;, 16384);</span><br><span class="line">        &#x2F;&#x2F;等待时间</span><br><span class="line">        props.put(&quot;linger.ms&quot;, 1);</span><br><span class="line">        &#x2F;&#x2F;RecordAccumulator 缓冲区大小</span><br><span class="line">        props.put(&quot;buffer.memory&quot;, 33554432);</span><br><span class="line">        props.put(&quot;key.serializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;value.serializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        for (int i &#x3D; 0; i &lt; 100; i++) &#123;</span><br><span class="line">            producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;,</span><br><span class="line">            Integer.toString(i), Integer.toString(i)));</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>*<em>带回调函数的 API  *</em></p>
<p><strong>回调函数会在 producer 收到 ack 时调用，为异步调用</strong>， 该方法有两个参数，分别是RecordMetadata 和 Exception，如果 Exception 为 null，说明消息发送成功，如果Exception 不为 null，说明消息发送失败。<br>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; 100; i++) &#123;</span><br><span class="line">    producer.send(new ProducerRecord&lt;String, String&gt;(&quot;first&quot;,</span><br><span class="line">    Integer.toString(i), Integer.toString(i)), new Callback() &#123;</span><br><span class="line">        &#x2F;&#x2F;回调函数， 该方法会在 Producer 收到 ack 时调用，为异步调用</span><br><span class="line">        @Override</span><br><span class="line">        public void onCompletion(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">            if (exception &#x3D;&#x3D; null) &#123;</span><br><span class="line">                System.out.println(&quot;success-&gt;&quot; +metadata.offset());</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                exception.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ol>
</li>
</ol>
<h2 id="3-2-Consumer-API"><a href="#3-2-Consumer-API" class="headerlink" title="3.2 Consumer API"></a>3.2 Consumer API</h2><p>Consumer 消费数据时的可靠性是很容易保证的，因为数据在 Kafka 中是持久化的，故不用担心数据丢失问题。<br>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。<br>所以 <strong>offset 的维护是 Consumer 消费数据是必须考虑的问题。</strong></p>
<h3 id="3-2-1-自动提交offset"><a href="#3-2-1-自动提交offset" class="headerlink" title="3.2.1 自动提交offset"></a>3.2.1 自动提交offset</h3><ol>
<li><p>编写代码</p>
<p>需要用到的类：<br><strong>KafkaConsumer</strong>： 需要创建一个消费者对象，用来消费数据<br><strong>ConsumerConfig</strong>： 获取所需的一系列配置参数<br><strong>ConsuemrRecord</strong>： 每条数据都要封装成一个 ConsumerRecord 对象<br>为了使我们能够专注于自己的业务逻辑， Kafka 提供了自动提交 offset 的功能。自动提交 offset 的相关参数：<br><strong>enable.auto.commit</strong>： 是否开启自动提交 offset 功能<br><strong>auto.commit.interval.ms</strong>： 自动提交 offset 的时间间隔  </p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line">import org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line">import org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class CustomConsumer &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">    </span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);</span><br><span class="line">        props.put(&quot;group.id&quot;, &quot;test&quot;);</span><br><span class="line">        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);</span><br><span class="line">        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);</span><br><span class="line">        props.put(&quot;key.deserializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        props.put(&quot;value.deserializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        </span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(&quot;first&quot;));</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100);</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records)</span><br><span class="line">            	System.out.printf(&quot;offset &#x3D; %d, key &#x3D; %s, value &#x3D; %s%n&quot;, record.offset(), record.key(), record.value());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-手动提交offset"><a href="#3-2-2-手动提交offset" class="headerlink" title="3.2.2 手动提交offset"></a>3.2.2 手动提交offset</h3><p>虽然自动提交 offset 十分简介便利，但由于其是基于时间提交的， 开发人员难以把握offset 提交的时机。因此 Kafka 还提供了手动提交 offset 的 API。手动提交 offset 的方法有两种：分别是 <strong>commitSync（同步提交）</strong> 和 <strong>commitAsync（异步提交）</strong> 。两者的相同点是，都会将本次 poll 的一批数据最高的偏移量提交；不同点是，commitSync 阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而 commitAsync 则没有失败重试机制，故有可能提交失败。  </p>
<ul>
<li><p><strong>异步提交offset</strong></p>
<p>虽然同步提交 offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式。<br>以下为异步提交 offset 的示例：  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka.consumer;</span><br><span class="line"></span><br><span class="line">import org.apache.kafka.clients.consumer.*;</span><br><span class="line">import org.apache.kafka.common.TopicPartition;</span><br><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.Map;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class CustomConsumer &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">    </span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        &#x2F;&#x2F;Kafka 集群</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);</span><br><span class="line">        &#x2F;&#x2F;消费者组，只要 group.id 相同，就属于同一个消费者组</span><br><span class="line">        props.put(&quot;group.id&quot;, &quot;test&quot;);</span><br><span class="line">        &#x2F;&#x2F;关闭自动提交 offset</span><br><span class="line">        props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);</span><br><span class="line">        props.put(&quot;key.deserializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        props.put(&quot;value.deserializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props);</span><br><span class="line">        consumer.subscribe(Arrays.asList(&quot;first&quot;));&#x2F;&#x2F;消费者订阅主题</span><br><span class="line">        while (true) &#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100);&#x2F;&#x2F;消费者拉取数据</span><br><span class="line">            for (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.printf(&quot;offset &#x3D; %d, key &#x3D; %s, value &#x3D; %s%n&quot;, record.offset(), record.key(), record.value());</span><br><span class="line">            &#125;</span><br><span class="line">            &#x2F;&#x2F;异步提交</span><br><span class="line">            consumer.commitAsync(new OffsetCommitCallback() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) &#123;</span><br><span class="line">                    if (exception !&#x3D; null) &#123;</span><br><span class="line">                    	System.err.println(&quot;Commit failed for&quot; + offsets);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="3-3-自定义Interceptor"><a href="#3-3-自定义Interceptor" class="headerlink" title="3.3 自定义Interceptor"></a>3.3 自定义Interceptor</h2><h3 id="3-3-1-拦截器原理"><a href="#3-3-1-拦截器原理" class="headerlink" title="3.3.1 拦截器原理"></a>3.3.1 拦截器原理</h3><p>Producer 拦截器(interceptor)是在 Kafka 0.10 版本被引入的，主要用于<strong>实现 clients 端的定制化控制逻辑。</strong><br>对于 producer 而言， interceptor 使得用户<strong>在消息发送前</strong>以及 <strong>producer 回调逻辑前</strong>有机会对消息做一些定制化需求，比如修改消息等。同时， producer 允许用户指定多个 interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。 Intercetpor 的实现接口是<strong>org.apache.kafka.clients.producer.ProducerInterceptor</strong>，其定义的方法包括：  </p>
<p>（1） <strong>configure(configs)</strong>：<br>获取配置信息和初始化数据时调用。<br>（2） <strong>onSend(ProducerRecord)</strong>：<br>该方法封装进 KafkaProducer.send 方法中，即它运行在用户主线程中。 Producer 确保在消息被序列化以及计算分区前调用该方法。 用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的 topic 和分区， 否则会影响目标分区的计算。<br>（3） <strong>onAcknowledgement(RecordMetadata, Exception)</strong>：<br>该方法会在消息从 RecordAccumulator 成功发送到 Kafka Broker 之后，或者在发送过程中失败时调用。 并且通常都是在 producer 回调逻辑触发之前。 onAcknowledgement 运行在producer 的 IO 线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢 producer 的消息发送效率。<br>（4） <strong>close</strong>：<br>关闭 interceptor，主要用于执行一些资源清理工作。</p>
<p>如前所述， interceptor 可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外倘若指定了多个 interceptor，则 producer 将按照指定顺序调用它们，并仅仅是捕获每个 interceptor 可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。  </p>
<h3 id="3-3-2-拦截器案例"><a href="#3-3-2-拦截器案例" class="headerlink" title="3.3.2 拦截器案例"></a>3.3.2 拦截器案例</h3><ol>
<li><p><strong>需求：</strong></p>
<p>实现一个简单的双 interceptor 组成的拦截链。第一个 interceptor 会在消息发送前将时间戳信息加到消息 value 的最前部；第二个 interceptor 会在消息发送后更新成功发送消息数或失败发送消息数。</p>
<p><img src="https://i.loli.net/2021/08/29/4N1kchtIQYpRix5.png" alt="image-20210829160513448"></p>
</li>
<li><p><strong>案例实操</strong></p>
<ol>
<li><p>增加时间戳拦截器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka.interceptor;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line">import org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line">public class TimeInterceptor implements ProducerInterceptor&lt;String, String&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; configs) &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;</span><br><span class="line">        &#x2F;&#x2F; 创建一个新的 record，把时间戳写入消息体的最前部</span><br><span class="line">        return new ProducerRecord(record.topic(),record.partition(), record.timestamp(), record.key(),System.currentTimeMillis() + &quot;,&quot; + record.value().toString());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public void close() &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka.interceptor;</span><br><span class="line"></span><br><span class="line">import java.util.Map;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerInterceptor;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line">import org.apache.kafka.clients.producer.RecordMetadata;</span><br><span class="line"></span><br><span class="line">public class CounterInterceptor implements ProducerInterceptor&lt;String, String&gt;&#123;</span><br><span class="line"></span><br><span class="line">    private int errorCounter &#x3D; 0;</span><br><span class="line">    private int successCounter &#x3D; 0;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; configs) &#123;</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; record) &#123;</span><br><span class="line">    	return record;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public void onAcknowledgement(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">        &#x2F;&#x2F; 统计成功和失败的次数</span><br><span class="line">        if (exception &#x3D;&#x3D; null) &#123;</span><br><span class="line">        successCounter++;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">        errorCounter++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    @Override</span><br><span class="line">    public void close() &#123;</span><br><span class="line">        &#x2F;&#x2F; 保存结果</span><br><span class="line">        System.out.println(&quot;Successful sent: &quot; + successCounter);</span><br><span class="line">        System.out.println(&quot;Failed sent: &quot; + errorCounter);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Producer主程序</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.kafka.interceptor;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line">import java.util.Properties;</span><br><span class="line">import org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line">import org.apache.kafka.clients.producer.Producer;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line">import org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line">public class InterceptorProducer &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        &#x2F;&#x2F; 1 设置配置信息</span><br><span class="line">        Properties props &#x3D; new Properties();</span><br><span class="line">        props.put(&quot;bootstrap.servers&quot;, &quot;hadoop102:9092&quot;);</span><br><span class="line">        props.put(&quot;acks&quot;, &quot;all&quot;);</span><br><span class="line">        props.put(&quot;retries&quot;, 3);</span><br><span class="line">        props.put(&quot;batch.size&quot;, 16384);</span><br><span class="line">        props.put(&quot;linger.ms&quot;, 1);</span><br><span class="line">        props.put(&quot;buffer.memory&quot;, 33554432);</span><br><span class="line">        props.put(&quot;key.serializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        props.put(&quot;value.serializer&quot;,</span><br><span class="line">        &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; 2 构建拦截链</span><br><span class="line">        List&lt;String&gt; interceptors &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">        interceptors.add(&quot;com.atguigu.kafka.interceptor.TimeInterceptor&quot;);</span><br><span class="line">        interceptors.add(&quot;com.atguigu.kafka.interceptor.CounterInterceptor&quot;);</span><br><span class="line">        props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);</span><br><span class="line">        String topic &#x3D; &quot;first&quot;;</span><br><span class="line">        Producer&lt;String, String&gt; producer &#x3D; new KafkaProducer&lt;&gt;(props);</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; 3 发送消息</span><br><span class="line">        for (int i &#x3D; 0; i &lt; 10; i++) &#123;</span><br><span class="line">            ProducerRecord&lt;String, String&gt; record &#x3D; new ProducerRecord&lt;&gt;(topic, &quot;message&quot; + i);</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; 4 一定要关闭 producer，这样才会调用 interceptor 的 close 方法</span><br><span class="line">        producer.close();</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试</p>
<p>在 kafka 上启动消费者， 然后运行客户端 java 程序。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning --topic first</span><br><span class="line"></span><br><span class="line">1501904047034,message0</span><br><span class="line">1501904047225,message1</span><br><span class="line">1501904047230,message2</span><br><span class="line">1501904047234,message3</span><br><span class="line">1501904047236,message4</span><br><span class="line">1501904047240,message5</span><br><span class="line">1501904047243,message6</span><br><span class="line">1501904047246,message7</span><br><span class="line">1501904047249,message8</span><br><span class="line">1501904047252,message9</span><br></pre></td></tr></table></figure>

</li>
</ol>
</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/04/02/%E5%A4%A7%E6%95%B0%E6%8D%AELinux%E5%BC%80%E5%8F%91/" rel="prev" title="大数据Linux开发">
      <i class="fa fa-chevron-left"></i> 大数据Linux开发
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/08/28/Hive/" rel="next" title="Hive">
      Hive <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          المحتويات
        </li>
        <li class="sidebar-nav-overview">
          عام
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Kafka概述"><span class="nav-number">1.</span> <span class="nav-text">1 Kafka概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-定义"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-消息队列"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 消息队列</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-传统消息队列的应用场景"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.2.1 传统消息队列的应用场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-消息队列的两种模式"><span class="nav-number">1.2.2.</span> <span class="nav-text">1.2.2 消息队列的两种模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-Kafka基础架构"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 Kafka基础架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Kafka架构深入"><span class="nav-number">2.</span> <span class="nav-text">2 Kafka架构深入</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Kafka工作流程及文件存储机制"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 Kafka工作流程及文件存储机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Kafka生产者"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Kafka生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-分区策略"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1 分区策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-数据可靠性保证"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2 数据可靠性保证</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-3-Exactly-Once-语义"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3 Exactly Once 语义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Kafka消费者"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Kafka消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-消费方式"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.1 消费方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-分区分配策略"><span class="nav-number">2.3.2.</span> <span class="nav-text">2.3.2 分区分配策略</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-3-offset的维护"><span class="nav-number">2.3.3.</span> <span class="nav-text">2.3.3 offset的维护</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-Kafka高效读写数据"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 Kafka高效读写数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-Zookeeper在Kafka中的作用"><span class="nav-number">2.5.</span> <span class="nav-text">2.5 Zookeeper在Kafka中的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-Kafka事务"><span class="nav-number">2.6.</span> <span class="nav-text">2.6 Kafka事务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-Producer事务"><span class="nav-number">2.6.1.</span> <span class="nav-text">2.6.1 Producer事务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-2-Consumer事务"><span class="nav-number">2.6.2.</span> <span class="nav-text">2.6.2 Consumer事务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Kafka-API"><span class="nav-number">3.</span> <span class="nav-text">3 Kafka API</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Producer-API"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Producer API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-消息发送流程"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1 消息发送流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-异步发送API"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2 异步发送API</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Consumer-API"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 Consumer API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-自动提交offset"><span class="nav-number">3.2.1.</span> <span class="nav-text">3.2.1 自动提交offset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-手动提交offset"><span class="nav-number">3.2.2.</span> <span class="nav-text">3.2.2 手动提交offset</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-自定义Interceptor"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 自定义Interceptor</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-1-拦截器原理"><span class="nav-number">3.3.1.</span> <span class="nav-text">3.3.1 拦截器原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-2-拦截器案例"><span class="nav-number">3.3.2.</span> <span class="nav-text">3.3.2 拦截器案例</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">黎达</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">المقالات</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">التصنيفات</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">35</span>
        <span class="site-state-item-name">الوسوم</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">黎达</span>
</div>
  <div class="powered-by">تطبيق الموقع <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
